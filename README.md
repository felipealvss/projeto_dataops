# ğŸš€ **Projeto DataOps Unifor**

![Docker](https://img.shields.io/badge/Docker-orange) ![Airflow](https://img.shields.io/badge/Airflow-blue) ![Airflow](https://img.shields.io/badge/MongoDB-green) ![Poetry](https://img.shields.io/badge/Poetry-yellow) ![Postgres](https://img.shields.io/badge/Postgres-blue) ![FastAPI](https://img.shields.io/badge/FastAPI-purple.svg) ![Streamlit](https://img.shields.io/badge/Streamlit-red.svg)

O **Projeto DataOps Unifor** Ã© um projeto de engenharia de dados que orquestra pipelines de dados, realiza transformaÃ§Ãµes de forma sequencial e oferece visualizaÃ§Ãµes dinÃ¢micas e interativas. O projeto integra vÃ¡rias tecnologias para criar um fluxo de trabalho completo e automatizado de dados.

## ğŸ¯ **Objetivo do Projeto**

De forma geral, o objetivo principal Ã© automatizar o fluxo de dados atravÃ©s de pipelines orquestrados pelo **Apache Airflow** e utilizando containers **Docker** para isolar os serviÃ§os e garantir escalabilidade e eficiÃªncia. A soluÃ§Ã£o final inclui:

* **OrquestraÃ§Ã£o de Dados**: Gerenciamento de pipelines e execuÃ§Ã£o automÃ¡tica de tarefas.
* **TransformaÃ§Ãµes em Tempo Agendado**: Processamento de dados em forma de tarefas agendadas.
* **VisualizaÃ§Ã£o de Dados**: Dashboards interativos para monitoramentos e insights rÃ¡pidos.

---

## ğŸ“‹ **Diagrama do projeto**

- **Diagrama de alto nÃ­vel explicando o desenho das integraÃ§Ãµes entre as tecnologias:**

    <img src="docs/images/Diagrama02MermaidChart-2025-05-04.png" alt="Fluxo do projeto"/>

---

## ğŸ›  **Tecnologias e Ferramentas**

Este projeto utiliza um conjunto robusto de tecnologias para garantir a automaÃ§Ã£o, escalabilidade e facilidade de uso:

* **Docker**: ContainerizaÃ§Ã£o dos serviÃ§os para maior flexibilidade e isolamento.
* **Apache Airflow**: OrquestraÃ§Ã£o de workflows e agendamento de tarefas.
* **MongoDB Atlas**: Banco de dados NoSQL para dados nÃ£o estruturados.
* **PostgreSQL**: Banco de dados relacional para persistÃªncia de dados estruturados.
* **FastAPI**: Framework rÃ¡pido e moderno para a construÃ§Ã£o de APIs RESTful.
* **Streamlit**: Framework para criaÃ§Ã£o de dashboards interativos.
* **Redis**: Sistema de gerenciamento de cache e filas no Airflow.
* **Poetry**: Gerenciamento eficiente de dependÃªncias Python.

---

## ğŸ—‚ **OrganizaÃ§Ã£o da Estrutura do Projeto**

A estrutura do projeto foi organizada para ser intuitiva e modular, facilitando a navegaÃ§Ã£o e o desenvolvimento.

```plaintext
.
â”œâ”€â”€ config                       # Arquivos de configuraÃ§Ã£o do Airflow
â”œâ”€â”€ dags                         # DAGs do Airflow para orquestraÃ§Ã£o
â”‚   â”œâ”€â”€ dag_gerar_dados.py       # GeraÃ§Ã£o de dados
â”‚   â”œâ”€â”€ dag_vendas_ano_mes.py    # Processamento de vendas por ano e mÃªs
â”‚   â”œâ”€â”€ dag_vendas_estado.py     # Processamento de vendas por estado
â”‚   â””â”€â”€ dag_vendas_modalidade.py # Processamento de vendas por modalidade
â”œâ”€â”€ dataops_unifor               # MÃ³dulo principal
â”œâ”€â”€ docker                       # ConfiguraÃ§Ãµes Docker para FastAPI e Streamlit
â”œâ”€â”€ docs                         # DocumentaÃ§Ã£o adicional
â”œâ”€â”€ logs                         # Logs do Airflow
â”œâ”€â”€ plugins                      # Plugins customizados do Airflow
â”œâ”€â”€ src                          # CÃ³digo-fonte do projeto
â”‚   â”œâ”€â”€ fastapi_app              # AplicaÃ§Ã£o FastAPI
â”‚   â””â”€â”€ streamlit_dashboard      # Dashboard Streamlit
â””â”€â”€ tests                        # Testes do projeto
â””â”€â”€ .env                         # ConfiguraÃ§Ãµes de variÃ¡veis de ambiente
â”œâ”€â”€ docker-compose.yaml          # OrquestraÃ§Ã£o dos containers
â”œâ”€â”€ poetry.lock                  # Bloqueio de dependÃªncias
â”œâ”€â”€ pyproject.toml               # ConfiguraÃ§Ã£o do Poetry
â””â”€â”€ README.md                    # Este arquivo
```

---

## ğŸ“ **Como Rodar o Projeto**

### 1. **Instalar DependÃªncias**

Certifique-se de que o **Docker** e o **Docker Compose** estÃ£o instalados. Se nÃ£o, instale-os [aqui](https://www.docker.com/get-started).

Clone o repositÃ³rio e instale as dependÃªncias com o **Poetry**:

```bash
git clone https://github.com/felipealvss/projeto_dataops.git
cd projeto_dataops
poetry install --no-root
```

### 2. **Subir os Containers Docker**

Suba todos os containers definidos no arquivo `docker-compose.yaml`:

```bash
docker-compose up --build
```

Isso irÃ¡ iniciar os seguintes serviÃ§os:

* **PostgreSQL**: Banco de dados relacional.
* **Redis**: Gerenciador de filas para o Airflow.
* **Airflow**: OrquestraÃ§Ã£o de tarefas (DAGs).
* **FastAPI**: API backend.
* **Streamlit**: Dashboard interativo.

### 3. **Acessar os ServiÃ§os**

* **Airflow Web UI**: [http://localhost:8080](http://localhost:8080)
* **FastAPI**: [http://localhost:8000](http://localhost:8000)
* **Streamlit**: [http://localhost:8501](http://localhost:8501)

### 4. **Executar os DAGs**

Os DAGs podem ser visualizados e executados atravÃ©s da interface web do Airflow. Os DAGs disponÃ­veis sÃ£o:

* **dag\_gerar\_dados.py**: GeraÃ§Ã£o e ingestÃ£o de dados.
* **dag\_vendas\_ano\_mes.py**: Processamento de vendas por ano e mÃªs.
* **dag\_vendas\_estado.py**: Processamento de vendas por estado.
* **dag\_vendas\_modalidade.py**: Processamento de vendas por modalidade.

### 5. **Interagir com o painel Streamlit**

O painel Streamlit possui 3 botÃµes que interagem diretamente com as rotas disponÃ­veis da API:

* **Vendas por Modalidade**: InformaÃ§Ã£o agrupada de vendas por modalidade de pagamento.
* **Vendas por Cidade**: InformaÃ§Ã£o agrupada de vendas por cidade.
* **Vendas por Ano/MÃªs**: InformaÃ§Ã£o agrupada de vendas por ano/mÃªs.

---

## âš™ **Estrutura do `docker-compose.yaml`**

Este arquivo orquestra os serviÃ§os Docker. Ele inclui:

* **Airflow**: ConfiguraÃ§Ã£o dos containers para o `webserver`, `scheduler`, `worker`, `dag-processor`, e `triggerer`.
* **PostgreSQL**: Banco de dados relacional utilizado pelo Airflow.
* **Redis**: Broker de filas para o Airflow.
* **FastAPI e Streamlit**: Containers para o backend e visualizaÃ§Ã£o de dados.

---

## ğŸ§ª **Como Testar**

O projeto inclui testes automatizados. Atualmente, os testes cobrem a API **FastAPI** e podem ser executados com:

```bash
python tests/test_api.py
```

---

## ğŸ¤ **ContribuiÃ§Ã£o**

ContribuiÃ§Ãµes sÃ£o sempre bem-vindas! Para contribuir:

1. FaÃ§a um **fork** deste repositÃ³rio.
2. Crie uma nova branch para sua feature:
   `git checkout -b feature/nome-da-feature`
3. FaÃ§a as alteraÃ§Ãµes e adicione um commit:
   `git commit -am 'Adicionando nova feature'`
4. FaÃ§a o push para sua branch:
   `git push origin feature/nome-da-feature`
5. Abra um **Pull Request** explicando as mudanÃ§as.

---

## ğŸ“„ **LicenÃ§a**

Este projeto estÃ¡ licenciado sob a **MIT License**. Veja o arquivo [LICENSE](LICENSE) para mais detalhes.

---
