
## üìå **Roadmap T√©cnico ‚Äì Projeto DataOps Unifor**

### üîß 1. **Configura√ß√£o do Ambiente Base**

* **Objetivo**: Preparar o ambiente de desenvolvimento e execu√ß√£o utilizando cont√™ineres.
* **A√ß√µes**:

  * Configurar o `docker-compose.yaml` utilizando a imagem oficial do Airflow com CeleryExecutor.
  * Definir servi√ßos para: Airflow (webserver, scheduler, workers), PostgreSQL, FastAPI, e Streamlit.
  * Incluir vari√°veis no `.env` com URIs, credenciais e caminhos utilizados pelos servi√ßos.
* **Diret√≥rios envolvidos**: `docker`, `.env`, `docker-compose.yaml`, `README.md`.

---

### üóÇÔ∏è 2. **Organiza√ß√£o da Estrutura do Projeto**

* **Objetivo**: Manter a modularidade e escalabilidade do sistema.
* **A√ß√µes**:

  * Estruturar os diret√≥rios conforme seu modelo (ex: `src/`, `dags/`, `config/`, `plugins/`, `tests/`, `docs/`).
  * Usar `pyproject.toml` e `poetry.lock` para o controle de depend√™ncias no projeto como um todo.
* **Diret√≥rios envolvidos**: Toda a arquitetura definida.

---

### üìÖ 3. **Orquestra√ß√£o com Airflow**

* **Objetivo**: Automatizar a gera√ß√£o, transforma√ß√£o e carga de dados.
* **A√ß√µes**:

  * Criar a DAG `dag_gerar_dados.py` para gerar e enviar dados simulados para o **MongoDB Atlas**.
  * Implementar as DAGs:

    * `dag_vendas_ano_mes.py`
    * `dag_vendas_estado.py`
    * `dag_vendas_modalidade.py`

    > Todas se conectam ao MongoDB Atlas, realizam transforma√ß√µes espec√≠ficas e carregam os dados em tabelas PostgreSQL.
* **Diret√≥rios envolvidos**: `dags/`, `config/`, `plugins/`.

---

### üß© 4. **Modelagem e Acesso aos Dados**

* **Objetivo**: Estruturar e disponibilizar os dados transformados via API.
* **A√ß√µes**:

  * Modelar tabelas no PostgreSQL de acordo com os formatos de sa√≠da das DAGs.
  * Desenvolver rotas no FastAPI que consultam cada uma dessas tabelas e retornam dados em JSON.
  * Configurar container para o FastAPI dentro de `src/fastapi_app`.
* **Diret√≥rios envolvidos**: `src/fastapi_app`, `docker/`, `tests/`.

---

### üìä 5. **Visualiza√ß√£o e Monitoramento com Streamlit**

* **Objetivo**: Permitir a visualiza√ß√£o dos dados em tempo real.
* **A√ß√µes**:

  * Criar uma interface no `dashboard.py` que consuma:

    * As cole√ß√µes originais no MongoDB Atlas.
    * As rotas do FastAPI conectadas ao PostgreSQL.
  * Atualizar o dashboard com refresh autom√°tico a cada minuto.
  * Manter c√≥digo em `src/streamlit_dashboard`.
* **Diret√≥rios envolvidos**: `src/streamlit_dashboard`, `docker/`.

---

### üß™ 6. **Testes e Valida√ß√£o**

* **Objetivo**: Garantir a robustez e a qualidade do pipeline.
* **A√ß√µes**:

  * Escrever testes unit√°rios para fun√ß√µes cr√≠ticas (transforma√ß√µes, API).
  * Validar DAGs no Airflow.
  * Garantir que todos os containers iniciem corretamente com `docker-compose up`.
* **Diret√≥rios envolvidos**: `tests/`, `logs/`.

---

### üìö 7. **Documenta√ß√£o e Manuten√ß√£o**

* **Objetivo**: Garantir a compreens√£o e continuidade do projeto.
* **A√ß√µes**:

  * Documentar o funcionamento das DAGs, API e Streamlit em `docs/`.
  * Atualizar o `README.md` com instru√ß√µes de uso, vari√°veis e endpoints.
  * Registrar o roadmap t√©cnico em `docs/roadmap.md`.

---

## üí° Estrat√©gias e Insights

* **Separa√ß√£o de responsabilidades**: Cada servi√ßo (Airflow, DB, API, Dashboard) √© isolado e independente, facilitando o monitoramento e manuten√ß√£o.
* **Escalabilidade**: O uso do CeleryExecutor no Airflow permite escalar workers conforme a carga.
* **Padroniza√ß√£o**: O uso do Poetry e da arquitetura modular garante controle sobre depend√™ncias e manuten√ß√£o do projeto.
* **Observabilidade**: Com Streamlit acessando dados brutos e transformados, √© poss√≠vel validar a integridade dos dados de ponta a ponta.

---
